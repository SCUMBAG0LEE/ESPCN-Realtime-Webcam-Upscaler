{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24f7146",
   "metadata": {
    "id": "f24f7146"
   },
   "source": [
    "# ESPCN Realtime Webcam Upscaler - Training Script (Google Colab)\n",
    "\n",
    "**Project:** ESPCN Realtime Webcam Upscaler  \n",
    "**Institution:** Universitas Tarumanagara  \n",
    "**Thesis:** Development Of An ESPCN Deep Learning Model For Real-Time Webcam Video Super-Resolution With Hardware Interference Optimization  \n",
    "**Platform:** Google Colab Cloud  \n",
    "**Date:** January 2026\n",
    "\n",
    "## Environment Specification\n",
    "- **OS:** Ubuntu 22.04.4 LTS (Colab Runtime)\n",
    "- **Python:** 3.10+\n",
    "- **CPU:** Intel Xeon E5-2699 v4 (1 Core / 2 Thread shared)\n",
    "- **RAM:** 13GB (shared)\n",
    "- **GPU:** NVIDIA T4 (optional, free tier) or higher\n",
    "- **Framework:** PyTorch 2.x with CUDA support\n",
    "\n",
    "## Overview\n",
    "This notebook implements ESPCN training in Google Colab with cloud storage integration. The pipeline:\n",
    "- Mounts Google Drive for persistent storage\n",
    "- Auto-configures batch size based on available GPU\n",
    "- Supports training on free T4 GPU or CPU fallback\n",
    "- Saves checkpoints and logs to Drive\n",
    "- Performs model quantization and ONNX export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29cbc29",
   "metadata": {
    "id": "e29cbc29"
   },
   "source": [
    "## 1. Library Imports\n",
    "\n",
    "Import all required libraries for training and cloud integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2675fdef",
   "metadata": {
    "id": "2675fdef"
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.transforms import ToTensor, ToPILImage, Compose, ColorJitter\n",
    "\n",
    "# Progress bar and utilities\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ONNX and inference\n",
    "import onnxruntime as ort\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# Google Drive integration (Colab-specific)\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JijEE4vT3O54",
   "metadata": {
    "id": "JijEE4vT3O54"
   },
   "source": [
    "## 2. Colab Environment Setup\n",
    "\n",
    "Install dependencies and mount Google Drive for persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kJzDUghQ3PUg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJzDUghQ3PUg",
    "outputId": "6537910a-568d-4eec-9d8b-2a2d2de14d09"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies...\")\n",
    "get_ipython().run_line_magic('pip', 'install pytorch-msssim onnxruntime-gpu -q')\n",
    "print(\"âœ“ Dependencies installed\\n\")\n",
    "\n",
    "# Import ssim after installation\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# ========== MOUNT GOOGLE DRIVE ==========\n",
    "if not os.path.exists('/content/drive/MyDrive'):\n",
    "    print(\"ðŸ“ Mounting Google Drive...\")\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ“ Google Drive mounted\\n\")\n",
    "else:\n",
    "    print(\"âœ“ Google Drive already mounted\\n\")\n",
    "\n",
    "# ========== COPY DATASETS FROM DRIVE ==========\n",
    "if not os.path.exists('/content/datasets'):\n",
    "    print(\"ðŸ“‹ Copying datasets from Google Drive...\")\n",
    "    print(\"  Note: This may take 2-5 minutes depending on dataset size\")\n",
    "    os.system('sudo cp -rf /content/drive/MyDrive/Thesis/datasets /content/datasets')\n",
    "    print(\"âœ“ Datasets copied\\n\")\n",
    "else:\n",
    "    print(\"âœ“ Datasets already available locally\\n\")\n",
    "\n",
    "# ========== AUTO-CONFIGURE BATCH SIZE ==========\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ðŸŽ® GPU detected: {gpu_name}\")\n",
    "    \n",
    "    if \"T4\" in gpu_name:\n",
    "        BATCH_SIZE = 128\n",
    "        print(\"   â†’ Using T4 GPU with BATCH_SIZE=128\")\n",
    "    elif \"V100\" in gpu_name or \"A100\" in gpu_name:\n",
    "        BATCH_SIZE = 256\n",
    "        print(\"   â†’ Using high-end GPU with BATCH_SIZE=256\")\n",
    "    else:\n",
    "        BATCH_SIZE = 64\n",
    "        print(f\"   â†’ Using {gpu_name} with BATCH_SIZE=64\")\n",
    "else:\n",
    "    BATCH_SIZE = 64\n",
    "    print(\"ðŸ’» CPU-only mode detected\")\n",
    "    print(\"   â†’ Using BATCH_SIZE=64 (slower but works)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09162a59",
   "metadata": {
    "id": "09162a59"
   },
   "source": [
    "## 3. Training Configuration & Hyperparameters\n",
    "\n",
    "Configure model architecture and training schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e96d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "731e96d0",
    "outputId": "282b4bb6-abd0-47f2-deb1-7c9d2f9b97f9"
   },
   "outputs": [],
   "source": [
    "# ========================= CONFIGURATION =========================\n",
    "# Model Architecture\n",
    "UPSCALE_FACTOR = 2  # 2x upscaling\n",
    "\n",
    "# Training Hyperparameters\n",
    "EPOCHS = 150  # Total training epochs\n",
    "PATCH_SIZE = 256  # Training patch size\n",
    "LEARNING_RATE = 1e-4  # Adam optimizer learning rate\n",
    "LOSS_ALPHA = 0.84  # Weight for MSE loss\n",
    "\n",
    "# Hardware Configuration (BATCH_SIZE set above based on GPU)\n",
    "NUM_WORKER = os.cpu_count()  # Use all available CPU cores\n",
    "print(f\"ðŸ”§ Configuration:\")\n",
    "print(f\"   Upscale Factor: {UPSCALE_FACTOR}x\")\n",
    "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE:.0e}\")\n",
    "print(f\"   Loss Alpha (MSE weight): {LOSS_ALPHA}\")\n",
    "print(f\"   DataLoader Workers: {NUM_WORKER}\\n\")\n",
    "\n",
    "# Directory Structure (using Google Drive paths for persistence)\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/Thesis\")\n",
    "DATA_DIR = Path(\"/content/datasets\")\n",
    "OUTPUTS_DIR = BASE_DIR / \"outputs\"\n",
    "CHECKPOINTS_DIR = BASE_DIR / \"checkpoints\"\n",
    "CHECKPOINT_FILE = CHECKPOINTS_DIR / f\"best_espcn_x{UPSCALE_FACTOR}.pth\"\n",
    "\n",
    "# ========================= REPRODUCIBILITY =========================\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    \"\"\"Set seed for DataLoader worker processes.\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b70ea",
   "metadata": {
    "id": "806b70ea"
   },
   "source": [
    "## 4. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d01f6",
   "metadata": {
    "id": "4d4d01f6"
   },
   "outputs": [],
   "source": [
    "def prepare_environment_and_datasets(patch_size):\n",
    "    \"\"\"Prepare training environment and validate datasets.\"\"\"\n",
    "    CHECKPOINTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "    OUTPUTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    CACHE_FILE_TRAIN = OUTPUTS_DIR / \"valid_train_paths.txt\"\n",
    "\n",
    "    # Validation dataset\n",
    "    valid_div2k_dir = DATA_DIR / \"DIV2K_valid_HR\"\n",
    "    validation_image_paths = glob.glob(str(valid_div2k_dir / '*.*'))\n",
    "\n",
    "    # Training dataset (with caching)\n",
    "    valid_train_paths = []\n",
    "    if CACHE_FILE_TRAIN.exists():\n",
    "        print(f\"Loading cached training paths...\")\n",
    "        try:\n",
    "            with open(CACHE_FILE_TRAIN, 'r') as f:\n",
    "                valid_train_paths = [line.strip() for line in f if line.strip()]\n",
    "            print(f\"âœ“ Loaded {len(valid_train_paths)} paths\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Cache error: {e}. Rebuilding...\")\n",
    "            valid_train_paths = []\n",
    "\n",
    "    if not valid_train_paths:\n",
    "        print(f\"Building training image list...\")\n",
    "        train_div2k_dir = DATA_DIR / \"DIV2K_train_HR\"\n",
    "        train_flickr2k_dir = DATA_DIR / \"Flickr2K_HR\"\n",
    "        personal_dir = DATA_DIR / \"Personal_HR\"\n",
    "\n",
    "        train_image_paths = glob.glob(str(train_div2k_dir / '*.*')) + \\\n",
    "                            glob.glob(str(train_flickr2k_dir / '*.*'))\n",
    "\n",
    "        if personal_dir.exists():\n",
    "            print(\"âœ“ Personal dataset found\")\n",
    "            train_image_paths += glob.glob(str(personal_dir / '*.*'))\n",
    "\n",
    "        print(f\"Found {len(train_image_paths)} candidate images\")\n",
    "\n",
    "        def is_image_large_enough(image_path, min_size):\n",
    "            try:\n",
    "                img = cv2.imread(str(image_path))\n",
    "                if img is None:\n",
    "                    return False\n",
    "                h, w = img.shape[:2]\n",
    "                return h >= min_size and w >= min_size\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        valid_train_paths = [\n",
    "            p for p in tqdm(train_image_paths, desc=\"Filtering\")\n",
    "            if is_image_large_enough(p, patch_size)\n",
    "        ]\n",
    "\n",
    "        print(f\"âœ“ Filtered: {len(valid_train_paths)}/{len(train_image_paths)} valid\")\n",
    "\n",
    "        try:\n",
    "            with open(CACHE_FILE_TRAIN, 'w') as f:\n",
    "                for path in valid_train_paths:\n",
    "                    f.write(f\"{path}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš  Cache write failed: {e}\")\n",
    "\n",
    "    if not valid_train_paths or not validation_image_paths:\n",
    "        raise RuntimeError(\"No datasets found. Check directory structure.\")\n",
    "\n",
    "    return valid_train_paths, validation_image_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1cbcd",
   "metadata": {
    "id": "a0a1cbcd"
   },
   "source": [
    "## 5. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85da2e21",
   "metadata": {
    "id": "85da2e21"
   },
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined MSE + SSIM loss for super-resolution.\"\"\"\n",
    "    def __init__(self, alpha=0.7):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.ssim_loss_fn = ssim\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        loss_mse = self.mse_loss(output, target)\n",
    "        ssim_score = self.ssim_loss_fn(output, target, data_range=1.0, size_average=True)\n",
    "        loss_ssim = 1 - ssim_score\n",
    "        total_loss = self.alpha * loss_mse + (1 - self.alpha) * loss_ssim\n",
    "        return total_loss, loss_mse, ssim_score\n",
    "\n",
    "\n",
    "def psnr(mse):\n",
    "    \"\"\"Calculate PSNR from MSE.\"\"\"\n",
    "    return 10 * math.log10(1 / mse) if mse > 0 else float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6698a64d",
   "metadata": {
    "id": "6698a64d"
   },
   "source": [
    "## 6. Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f942143",
   "metadata": {
    "id": "2f942143"
   },
   "outputs": [],
   "source": [
    "class TrainingSuperResolutionDataset(Dataset):\n",
    "    \"\"\"Training dataset with online augmentation.\"\"\"\n",
    "    def __init__(self, image_filenames, crop_size, upscale_factor):\n",
    "        super().__init__()\n",
    "        self.image_filenames = image_filenames\n",
    "        self.crop_size = crop_size - (crop_size % upscale_factor)\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.scale_factor = 1 / upscale_factor\n",
    "        self.transform = Compose([\n",
    "            ToPILImage(),\n",
    "            ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            hr_image = cv2.imread(self.image_filenames[index])\n",
    "            if hr_image is None:\n",
    "                raise IOError(f\"Failed to load image\")\n",
    "            hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            return self.__getitem__((index + 1) % len(self))\n",
    "\n",
    "        h, w = hr_image.shape[:2]\n",
    "        i = random.randint(0, h - self.crop_size)\n",
    "        j = random.randint(0, w - self.crop_size)\n",
    "        hr_patch = hr_image[i:i+self.crop_size, j:j+self.crop_size, :]\n",
    "\n",
    "        if torch.rand(1) > 0.5:\n",
    "            hr_patch = cv2.flip(hr_patch, 1)\n",
    "        if torch.rand(1) > 0.5:\n",
    "            angle = random.choice([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE])\n",
    "            hr_patch = cv2.rotate(hr_patch, angle)\n",
    "\n",
    "        hr_patch_tensor = self.transform(hr_patch)\n",
    "        lr_patch_tensor = F.interpolate(\n",
    "            hr_patch_tensor.unsqueeze(0), scale_factor=self.scale_factor,\n",
    "            mode='bicubic', align_corners=False, antialias=True\n",
    "        ).squeeze(0)\n",
    "\n",
    "        return lr_patch_tensor, hr_patch_tensor\n",
    "\n",
    "\n",
    "class ValidationSuperResolutionDataset(Dataset):\n",
    "    \"\"\"Validation dataset without augmentation.\"\"\"\n",
    "    def __init__(self, image_filenames, upscale_factor):\n",
    "        super().__init__()\n",
    "        self.image_filenames = image_filenames\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.to_tensor = ToTensor()\n",
    "        self.scale_factor = 1 / upscale_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            hr_image = cv2.imread(self.image_filenames[index])\n",
    "            if hr_image is None:\n",
    "                raise IOError()\n",
    "            hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            return self.__getitem__((index + 1) % len(self))\n",
    "\n",
    "        h, w = hr_image.shape[:2]\n",
    "        w_new, h_new = w - (w % self.upscale_factor), h - (h % self.upscale_factor)\n",
    "        hr_image = hr_image[:h_new, :w_new, :]\n",
    "\n",
    "        hr_tensor = self.to_tensor(hr_image)\n",
    "        lr_tensor = F.interpolate(\n",
    "            hr_tensor.unsqueeze(0), scale_factor=self.scale_factor,\n",
    "            mode='bicubic', align_corners=False, antialias=True\n",
    "        ).squeeze(0)\n",
    "\n",
    "        return lr_tensor, hr_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e70967",
   "metadata": {
    "id": "a9e70967"
   },
   "source": [
    "## 7. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ccae0",
   "metadata": {
    "id": "3e5ccae0"
   },
   "outputs": [],
   "source": [
    "class ESPCN(nn.Module):\n",
    "    \"\"\"Efficient Sub-Pixel Convolutional Neural Network.\"\"\"\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(ESPCN, self).__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 3 * (upscale_factor ** 2), kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pixel_shuffle(self.conv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250a4ae",
   "metadata": {
    "id": "d250a4ae"
   },
   "source": [
    "## 8. Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197dcee6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "197dcee6",
    "outputId": "de2824fc-e5f4-4669-e3b5-fbb0877f8721"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ESPCN TRAINING - GOOGLE COLAB\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Device: {DEVICE}\")\n",
    "    if DEVICE == \"cuda\":\n",
    "        print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "\n",
    "    # Prepare datasets\n",
    "    print(f\"\\nðŸ“ Preparing datasets...\")\n",
    "    train_paths, val_paths = prepare_environment_and_datasets(PATCH_SIZE)\n",
    "    \n",
    "    if not train_paths or not val_paths:\n",
    "        raise RuntimeError(\"Dataset preparation failed\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TrainingSuperResolutionDataset(train_paths, crop_size=PATCH_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
    "    val_dataset = ValidationSuperResolutionDataset(val_paths, upscale_factor=UPSCALE_FACTOR)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "        num_workers=min(4, NUM_WORKER),\n",
    "        pin_memory=(DEVICE == \"cuda\"),\n",
    "        worker_init_fn=seed_worker\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=1, shuffle=False,\n",
    "        num_workers=min(4, NUM_WORKER),\n",
    "        pin_memory=(DEVICE == \"cuda\")\n",
    "    )\n",
    "\n",
    "    print(f\"âœ“ Training samples: {len(train_dataset)}\")\n",
    "    print(f\"âœ“ Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "    # Initialize model\n",
    "    model = ESPCN(upscale_factor=UPSCALE_FACTOR).to(DEVICE)\n",
    "    if DEVICE == 'cuda' and torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\nðŸ§  Model: ESPCN x{UPSCALE_FACTOR} ({num_params:,} parameters)\")\n",
    "\n",
    "    # Initialize training components\n",
    "    criterion = CombinedLoss(alpha=LOSS_ALPHA).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "    scaler = GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "    # Setup checkpointing\n",
    "    start_epoch = 0\n",
    "    best_psnr = 0.0\n",
    "    log_file_path = OUTPUTS_DIR / 'training_log.csv'\n",
    "    training_log = []\n",
    "\n",
    "    if CHECKPOINT_FILE.exists():\n",
    "        print(f\"\\nâ†» Loading checkpoint...\")\n",
    "        checkpoint = torch.load(CHECKPOINT_FILE, map_location=DEVICE)\n",
    "        original_state_dict = checkpoint['model_state_dict']\n",
    "        new_state_dict = {}\n",
    "\n",
    "        needs_prefix_stripping = any(key.startswith('_orig_mod.') for key in original_state_dict.keys())\n",
    "        if needs_prefix_stripping:\n",
    "            for key, value in original_state_dict.items():\n",
    "                new_key = key[len('_orig_mod.'):] if key.startswith('_orig_mod.') else key\n",
    "                new_state_dict[new_key] = value\n",
    "        else:\n",
    "            new_state_dict = original_state_dict\n",
    "\n",
    "        needs_module_stripping = any(key.startswith('module.') for key in new_state_dict.keys())\n",
    "        if needs_module_stripping:\n",
    "            stripped_dict = {}\n",
    "            for key, value in new_state_dict.items():\n",
    "                new_key = key[len('module.'):] if key.startswith('module.') else key\n",
    "                stripped_dict[new_key] = value\n",
    "            new_state_dict = stripped_dict\n",
    "\n",
    "        model.load_state_dict(new_state_dict)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_psnr = checkpoint.get('best_psnr', 0.0)\n",
    "        print(f\"   âœ“ Resumed from epoch {start_epoch} (best PSNR: {best_psnr:.4f} dB)\")\n",
    "\n",
    "        if log_file_path.exists():\n",
    "            try:\n",
    "                log_df = pd.read_csv(log_file_path)\n",
    "                log_df = log_df[log_df['epoch'] < start_epoch]\n",
    "                training_log = log_df.to_dict('records')\n",
    "            except:\n",
    "                training_log = []\n",
    "    else:\n",
    "        print(f\"\\nâ–¶ Starting training from scratch\")\n",
    "        if log_file_path.exists():\n",
    "            log_file_path.unlink()\n",
    "\n",
    "    # Enable torch.compile if available\n",
    "    try:\n",
    "        print(f\"Compiling model with torch.compile...\")\n",
    "        model = torch.compile(model)\n",
    "    except Exception as e:\n",
    "        print(f\"âš  torch.compile failed: {e}. Using eager mode.\")\n",
    "\n",
    "    # Begin training\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING ESPCN x{UPSCALE_FACTOR} | Epochs {start_epoch+1}-{EPOCHS}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        model.train()\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        for lr_images, hr_images in progress_bar:\n",
    "            lr_images = lr_images.to(DEVICE, non_blocking=(DEVICE == \"cuda\"))\n",
    "            hr_images = hr_images.to(DEVICE, non_blocking=(DEVICE == \"cuda\"))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if DEVICE == \"cuda\":\n",
    "                with autocast(device_type=DEVICE):\n",
    "                    outputs = model(lr_images)\n",
    "                    total_loss, mse, ssim_score = criterion(outputs.float(), hr_images.float())\n",
    "                scaler.scale(total_loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(lr_images)\n",
    "                total_loss, mse, ssim_score = criterion(outputs.float(), hr_images.float())\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                Loss=f\"{total_loss.item():.4f}\",\n",
    "                SSIM=f\"{ssim_score.item():.4f}\"\n",
    "            )\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_psnr, val_ssim = 0.0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (lr_images, hr_images) in enumerate(val_loader):\n",
    "                lr_images = lr_images.to(DEVICE)\n",
    "                hr_images = hr_images.to(DEVICE)\n",
    "                output = model(lr_images)\n",
    "                mse_val = nn.functional.mse_loss(output, hr_images)\n",
    "                val_psnr += psnr(mse_val.item())\n",
    "                val_ssim += ssim(output, hr_images, data_range=1.0, size_average=True).item()\n",
    "\n",
    "                if i == 0 and (epoch + 1) % 10 == 0:\n",
    "                    sr_pil = ToPILImage()(output.squeeze(0).cpu())\n",
    "                    output_path = OUTPUTS_DIR / f'val_epoch_{epoch+1:03d}.png'\n",
    "                    sr_pil.save(output_path)\n",
    "\n",
    "        avg_val_psnr = val_psnr / len(val_loader)\n",
    "        avg_val_ssim = val_ssim / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:3d} â”‚ PSNR: {avg_val_psnr:7.4f} dB â”‚ SSIM: {avg_val_ssim:.6f}\")\n",
    "\n",
    "        training_log.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'val_psnr': avg_val_psnr,\n",
    "            'val_ssim': avg_val_ssim,\n",
    "            'learning_rate': scheduler.get_last_lr()[0]\n",
    "        })\n",
    "\n",
    "        log_df = pd.DataFrame(training_log)\n",
    "        log_df.to_csv(log_file_path, index=False)\n",
    "        scheduler.step()\n",
    "\n",
    "        if avg_val_psnr > best_psnr:\n",
    "            best_psnr = avg_val_psnr\n",
    "            print(f\"  â†‘ New best PSNR: {best_psnr:.4f} dB. Saving...\")\n",
    "\n",
    "            model_state = model.state_dict()\n",
    "            needs_stripping = any(key.startswith('_orig_mod.') for key in model_state.keys())\n",
    "\n",
    "            if needs_stripping:\n",
    "                final_model_state = {\n",
    "                    key[len('_orig_mod.'):] if key.startswith('_orig_mod.') else key: value\n",
    "                    for key, value in model_state.items()\n",
    "                }\n",
    "            else:\n",
    "                final_model_state = model_state\n",
    "\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': final_model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_psnr': best_psnr,\n",
    "            }, CHECKPOINT_FILE)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ“ TRAINING COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "    print(f\"Best PSNR: {best_psnr:.4f} dB\\n\")\n",
    "\n",
    "    # Plot results\n",
    "    print(\"Generating training curves...\")\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(log_df['epoch'], log_df['val_psnr'], marker='o', linewidth=2, markersize=3)\n",
    "    plt.title('Validation PSNR vs. Epoch', fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(log_df['epoch'], log_df['val_ssim'], marker='o', linewidth=2, markersize=3, color='orange')\n",
    "    plt.title('Validation SSIM vs. Epoch', fontweight='bold')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('SSIM')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUTS_DIR / 'training_curves.png', dpi=150)\n",
    "    print(f\"âœ“ Curves saved to {OUTPUTS_DIR / 'training_curves.png'}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1KSQx28dzQI",
   "metadata": {
    "id": "e1KSQx28dzQI"
   },
   "source": [
    "## 9. FP16 Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OT6qOk-Ad2xu",
   "metadata": {
    "id": "OT6qOk-Ad2xu"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FP16 QUANTIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "quant_model = ESPCN(upscale_factor=UPSCALE_FACTOR).to(DEVICE)\n",
    "checkpoint = torch.load(CHECKPOINT_FILE, map_location=DEVICE)\n",
    "\n",
    "original_state_dict = checkpoint['model_state_dict']\n",
    "new_state_dict = {}\n",
    "needs_prefix_stripping = any(key.startswith('_orig_mod.') for key in original_state_dict.keys())\n",
    "if needs_prefix_stripping:\n",
    "    print(\"Stripping '_orig_mod.' prefix...\")\n",
    "    for key, value in original_state_dict.items():\n",
    "        new_key = key[len('_orig_mod.'):] if key.startswith('_orig_mod.') else key\n",
    "        new_state_dict[new_key] = value\n",
    "else:\n",
    "    new_state_dict = original_state_dict\n",
    "\n",
    "quant_model.load_state_dict(new_state_dict)\n",
    "quant_model.eval()\n",
    "quant_model.half()\n",
    "\n",
    "quantized_model_path = CHECKPOINTS_DIR / f\"best_espcn_x{UPSCALE_FACTOR}_fp16.pth\"\n",
    "torch.save(quant_model.state_dict(), quantized_model_path)\n",
    "print(f\"âœ“ FP16 model saved: {quantized_model_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nT7gxmzLgwrN",
   "metadata": {
    "id": "nT7gxmzLgwrN"
   },
   "source": [
    "## 10. ONNX Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vXI9Iz4XgyAN",
   "metadata": {
    "id": "vXI9Iz4XgyAN"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ONNX EXPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "EXPORT_FP16 = True\n",
    "\n",
    "if EXPORT_FP16:\n",
    "    print(f\"\\nExporting FP16 model...\")\n",
    "    onnx_model = ESPCN(upscale_factor=UPSCALE_FACTOR)\n",
    "    checkpoint_path_fp16 = CHECKPOINTS_DIR / f\"best_espcn_x{UPSCALE_FACTOR}_fp16.pth\"\n",
    "    onnx_model.load_state_dict(torch.load(checkpoint_path_fp16))\n",
    "    onnx_model.eval().half().to(DEVICE)\n",
    "    dummy_input = torch.randn(1, 3, 720, 1280, device=DEVICE).half()\n",
    "    onnx_model_path = OUTPUTS_DIR / f\"espcn_x{UPSCALE_FACTOR}_fp16.onnx\"\n",
    "else:\n",
    "    print(f\"\\nExporting FP32 model...\")\n",
    "    onnx_model = ESPCN(upscale_factor=UPSCALE_FACTOR).to(DEVICE)\n",
    "    checkpoint = torch.load(CHECKPOINT_FILE, map_location=DEVICE)\n",
    "\n",
    "    original_state_dict = checkpoint['model_state_dict']\n",
    "    new_state_dict = {}\n",
    "    needs_prefix_stripping = any(key.startswith('_orig_mod.') for key in original_state_dict.keys())\n",
    "\n",
    "    if needs_prefix_stripping:\n",
    "        print(\"Stripping '_orig_mod.' prefix...\")\n",
    "        for key, value in original_state_dict.items():\n",
    "            new_key = key[len('_orig_mod.'):] if key.startswith('_orig_mod.') else key\n",
    "            new_state_dict[new_key] = value\n",
    "    else:\n",
    "        new_state_dict = original_state_dict\n",
    "\n",
    "    onnx_model.load_state_dict(new_state_dict)\n",
    "    onnx_model.eval()\n",
    "    dummy_input = torch.randn(1, 3, 720, 1280, device=DEVICE)\n",
    "    onnx_model_path = OUTPUTS_DIR / f\"espcn_x{UPSCALE_FACTOR}.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    onnx_model, dummy_input, str(onnx_model_path),\n",
    "    export_params=True, do_constant_folding=True,\n",
    "    input_names=['input'], output_names=['output'],\n",
    "    dynamo=True,\n",
    "    dynamic_axes={'input': {2: 'height', 3: 'width'}, 'output': {2: 'height_out', 3: 'width_out'}},\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "print(f\"âœ“ ONNX model exported: {onnx_model_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jnf5DCUhhzop",
   "metadata": {
    "id": "jnf5DCUhhzop"
   },
   "source": [
    "## 11. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vaqAOnrmh1Fo",
   "metadata": {
    "id": "vaqAOnrmh1Fo"
   },
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BENCHMARKING\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Test input\n",
    "if EXPORT_FP16:\n",
    "    test_image_np = np.random.randn(1, 3, 720, 1280).astype(np.float16)\n",
    "else:\n",
    "    test_image_np = np.random.randn(1, 3, 720, 1280).astype(np.float32)\n",
    "\n",
    "test_image_torch = torch.from_numpy(test_image_np).to(DEVICE)\n",
    "if EXPORT_FP16:\n",
    "    test_image_torch = test_image_torch.half()\n",
    "\n",
    "# PyTorch benchmark\n",
    "print(\"Benchmarking PyTorch (100 iterations)...\")\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _ = onnx_model(test_image_torch)\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = onnx_model(test_image_torch)\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    pytorch_time = (time.time() - start_time) / 100\n",
    "\n",
    "print(f\"âœ“ PyTorch: {pytorch_time * 1000:.4f} ms/image\\n\")\n",
    "\n",
    "# ONNX benchmark\n",
    "print(\"Benchmarking ONNX Runtime (100 iterations)...\")\n",
    "session = ort.InferenceSession(str(onnx_model_path), providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "ort_inputs = {session.get_inputs()[0].name: test_image_np}\n",
    "_ = session.run(None, ort_inputs)\n",
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    _ = session.run(None, ort_inputs)\n",
    "onnx_time = (time.time() - start_time) / 100\n",
    "\n",
    "print(f\"âœ“ ONNX Runtime: {onnx_time * 1000:.4f} ms/image\\n\")\n",
    "\n",
    "# Results\n",
    "print(\"=\"*70)\n",
    "if pytorch_time > 0:\n",
    "    if onnx_time < pytorch_time:\n",
    "        speedup = (pytorch_time - onnx_time) / pytorch_time * 100\n",
    "        print(f\"âœ“ ONNX is ~{speedup:.1f}% faster than PyTorch\")\n",
    "    else:\n",
    "        slowdown = (onnx_time - pytorch_time) / pytorch_time * 100\n",
    "        print(f\"âš  ONNX is ~{slowdown:.1f}% slower than PyTorch\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
